{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:1.5em\">\n",
    "    <p>üìú Table des mati√®res:</p>\n",
    "    <ul>\n",
    "       <li><a href=\"#nltk\">Text Preprocessing with NLTK</a></li>  \n",
    "       <li>\n",
    "          <a href=\"#spacy\">Text Preprocessing with spaCy</a>\n",
    "       </li>\n",
    "       <li>\n",
    "          <a href=\"#ner\">Definig NER for nltk and spacy</a>\n",
    "       </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id =\"nltk\">Text Preprocessing with NLTK</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gisevciconia zero solution objet ordre virement Monsieur habit compte :_rib: 022 222 222 172 22 29576475 53 set agilisys zero solution swift agilamcxxx virer montant 89 250,00 dirais (quatre-vingt-neuf mille deux cent cinquante dirais de profit i parler export switzerland ian chez 0483 555 555 0266600 0 swift creschzz80a motif 22a005 signature agilisys industrie sara si√®ge social angle na rue ibn aisha boulevard abdelkrim el khattabi millim√®tre pari haan √©tage app√¢t nana gueulez amarrakech tu +212 (0) 999 99 6161 f +212 (0) 999 999 130 sara capital 500.000 000 des rcna35 33 if na 3939333 tina 3939 cnss:939 mt-103-stp 2838383393 et point pote trot cc cs con instance type and transmission de original receive from\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer , TreebankWordTokenizer,WordPunctTokenizer,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import contractions\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "import unicodedata\n",
    "from langdetect import detect\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def text_preprocessing(text,accented=True,tokenizer=WhitespaceTokenizer(),stopw=True,punctuation=True,lowercase=True,lemmatize=True,spelling=True,expand_contraction=True,urls=True):\n",
    "    if detect(text)=='en':\n",
    "        stopword =stopwords.words('english')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        spell = SpellChecker()\n",
    "    else :#if lang=\"french\"\n",
    "        stopword = stopwords.words('french')\n",
    "        lemmatizer = FrenchLefffLemmatizer()\n",
    "        spell = SpellChecker(language=\"fr\")\n",
    "    if lowercase:\n",
    "        #lowercase the text \n",
    "        text = text.lower()\n",
    "    if urls:\n",
    "        #remove urls\n",
    "        text=remove_urls(text)\n",
    "    #tokenize the text \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if expand_contraction:\n",
    "        #expand contractions\n",
    "        tokens = [contractions.fix(token) for token in tokens]\n",
    "    if punctuation:\n",
    "        #remove punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    if stopw:\n",
    "        #remove stopwords\n",
    "        tokens = [token for token in tokens if token not in stopword]\n",
    "    if accented:\n",
    "        tokens = [remove_accented_chars(token) for token in tokens]\n",
    "    if spelling:\n",
    "        #spell check:\n",
    "        tokens = [spell.correction(token) for token in tokens]\n",
    "    if lemmatize:\n",
    "        #lemmatization : \n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(word for word in tokens)\n",
    "\n",
    "    #Some tests:\n",
    "file = 'C:/Users/PC2/Downloads/test-ex.txt'\n",
    "f=open(file,'r')\n",
    "data = f.read()\n",
    "print(text_preprocessing(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id =\"spacy\">Text Preprocessing with spaCy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gisevciconia  aero solutions  Objet  ordre virement  monsieur   d√É  bit compte  _ rib  022 222 222 172 22 29576475 53  swt  agilisy aero solution  SWIFT  agilamcxx   virer montant  89 25000 Dirhams  quatrevingtneuf Dirhams     profit  CARLEX export Switzerland  IBAN  ch35 0483 555 555 0266600 0  SWIFT  creschzz80a  Motif  22A005  Signature   agilisy industrier sarl  Si√É  ge social  Angle n√Ç degr√© 2 rue ibn aicha bd Abdelkrim el khattabi imm Paris 2√Ç degr√© √¢  √£  tage appt n√¢ degr√© 23 gueliz √¢marrakech  t  212  0  999 99 6161 l f  212  0  999 999 130   sarl capital 500000 000 dhs  RCN√Ç degr√© 35 33  IF n√¢ degr√© 3939333  tpn√¢ degr√© 3939  cnss939  mt103stp 2838383393  mt Print   poet trot ccc cs econ instance type and transmission   Original received from \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now we ll do preprocessing using mainly spacy\n",
    "import spacy\n",
    "#load only french and english models tokenizers\n",
    "nlp_en = spacy.load(\"en_core_web_sm\", disable=['parser', 'tagger', 'ner'])\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\", disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def spacy_preprocessing(text,lowercase=True,stopw=True,punctuation=True,alphabetic=True,lemmatize=True,):\n",
    "    if detect(text)==\"en\":\n",
    "        nlp = nlp_en\n",
    "    else :\n",
    "        nlp = nlp_fr\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    remove_accented_chars(text)\n",
    "    #tokenize with spacy's default tokenizer\n",
    "    tokens = nlp(text)\n",
    "    if stopw :\n",
    "        tokens = [token for token in tokens if not token.is_stop]\n",
    "    if lemmatize :\n",
    "        tokens = [token.lemma_.strip() for token in tokens]\n",
    "    if punctuation :\n",
    "        tokens = [re.sub('<[^>]*>', '', token) for token in tokens]\n",
    "    if alphabetic:\n",
    "        tokens = [re.sub('[\\W]+','',token) for token in tokens]\n",
    "    return ' '.join(word for word in tokens)\n",
    "\n",
    "file = 'C:/Users/PC2/Downloads/test-ex.txt'\n",
    "f=open(file,'r')\n",
    "data = f.read()\n",
    "print(spacy_preprocessing(data,lowercase=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id =\"ner\">Definig NER for nltk and spacy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_nltk(text):\n",
    "    assert detect(text) =='en' 'text should be english to be parsed with nltk'\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_tokens  = nltk.pos_tag(tokens)\n",
    "    chunked = nltk.ne_chunk(tagged_tokens)\n",
    "    for chunk in chunked : \n",
    "        if hasattr(chunk,\"label\") and chunk.label == \"NE\":\n",
    "            print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_spacy(text):\n",
    "    if detect(text) == \"en\":\n",
    "        ner  = spacy.load(\"en_core_web_sm\",disable=[\"tagger\",\"parser\"])\n",
    "    else:\n",
    "        ner  = spacy.load(\"fr_core_news_sm\",disable=[\"tagger\",\"parser\"])\n",
    "    for ent in ner(text).ents:\n",
    "        print(ent.text,':',ent.label_,':',spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id =\"comp\">Comparing results before\\after preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messieurs : PER : Named person or family.\n",
      "AGILAMCXXX\n",
      "| : ORG : Companies, agencies, institutions, etc.\n",
      "Montant : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "Dirhams : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Mille deux cent cinquante : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Dirhams : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "CH35 : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "SWIFT : ORG : Companies, agencies, institutions, etc.\n",
      "CRESCHZZ80A\n",
      "\n",
      " \n",
      "\n",
      "Motif : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "INDUSTRIES SARL | : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "Angle n√Ç : PER : Named person or family.\n",
      "Abdelkrim el khattabi : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "Paris 2√Ç : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "√É : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "n√Ç : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "F : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "Capital : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "dhs | RCN√Ç : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "MT Print : PER : Named person or family.\n",
      "Instance Type and Transmission : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
     ]
    }
   ],
   "source": [
    "ner_spacy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gisevciconia zero : PER : Named person or family.\n",
      "ordre virement Monsieur : ORG : Companies, agencies, institutions, etc.\n",
      "zero solution swift : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "switzerland ian : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "el khattabi : ORG : Companies, agencies, institutions, etc.\n",
      "haan √©tage app√¢t nana gueulez : PER : Named person or family.\n",
      "cnss:939 mt-103-stp 2838383393 : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
     ]
    }
   ],
   "source": [
    "preprocessed_nltk=text_preprocessing(data)\n",
    "ner_spacy(preprocessed_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swt  agilisy aero solution  swift  agilamcxx    : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "dirhams     profit  carlex export switzerland  iban  ch35 : MISC : Miscellaneous entities, e.g. events, nationalities, products or works of art\n",
      "el khattabi : ORG : Companies, agencies, institutions, etc.\n",
      "paris : LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "dhs : ORG : Companies, agencies, institutions, etc.\n",
      "n√¢ : LOC : Non-GPE locations, mountain ranges, bodies of water\n"
     ]
    }
   ],
   "source": [
    "preprocessed_spacy=spacy_preprocessing(data,lowercase=False)\n",
    "ner_spacy(preprocessed_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77b840b16efc606bfe6fe465e16c80fde01359cf425f7f37ae28958c7f375ddc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
